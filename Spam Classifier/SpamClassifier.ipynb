{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72f79af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -U spacy\n",
    "!python -m spacy download en_core_web_trf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2715abcf-9ef9-4005-8c86-f3d9ac1349bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89f9a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import spacy\n",
    "def read_txt_files(directory):\n",
    "    data = []\n",
    "    for file in os.listdir(directory):\n",
    "        file_path = os.path.join(directory,file)\n",
    "        with open(file_path, 'r') as file:\n",
    "            data.append(file.read())        \n",
    "    return data\n",
    "        \n",
    "train_deceptive = read_txt_files('data/train/deceptive')\n",
    "train_truthful = read_txt_files('data/train/truthful')\n",
    "\n",
    "test_deceptive = read_txt_files('data/test/deceptive')\n",
    "test_truthful = read_txt_files('data/test/truthful')\n",
    "\n",
    "df_train_deceptive = pd.DataFrame({'content':train_deceptive, 'labels':np.zeros_like(320)})\n",
    "df_train_truthful = pd.DataFrame({'content':train_truthful, 'labels':np.ones_like(320)})\n",
    "df_train = pd.concat([df_train_deceptive,df_train_truthful])\n",
    "\n",
    "df_train = df_train.replace('\\n','', regex=True)\n",
    "\n",
    "df_test_deceptive = pd.DataFrame({'content':test_deceptive, 'labels':np.zeros_like(80)})\n",
    "df_test_truthful = pd.DataFrame({'content':test_truthful, 'labels':np.ones_like(80)})\n",
    "df_test = pd.concat([df_test_deceptive,df_test_truthful])\n",
    "\n",
    "df_test = df_test.replace('\\n','', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39622db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot figure(s)\n",
    "#Tokenize & Remove punctuation & Lemmatize & Remove numbers\n",
    "def tokenize_lemmatize_data(reviews):\n",
    "    nlp = spacy.load(\"en_core_web_trf\")\n",
    "    data = []\n",
    "    for review in reviews:\n",
    "        data.append([token.lemma_.lower() for token in nlp(review) if not token.is_stop and not token.is_punct])\n",
    "    return(data)\n",
    "        \n",
    "        \n",
    "data_train = tokenize_lemmatize_data(df_train['content']) \n",
    "data_test = tokenize_lemmatize_data(df_test['content']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f1edd6-2240-4067-8b40-b5abc1166eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train = [' '.join(text) for text in data_train]\n",
    "preprocessed_test = [' '.join(text) for text in data_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65939326-76cc-4630-a9f4-564beb1a2ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparamater_tune(clf,param_grid,X_train,y_train):\n",
    "    kf = KFold(n_splits=5, shuffle = True, random_state=0)\n",
    "    grid_search = GridSearchCV(\n",
    "        clf,\n",
    "        param_grid,\n",
    "        cv = kf,\n",
    "        scoring='accuracy'\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"Best parameters:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6608d0d2-a58f-4296-87c3-537ac7e228aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import KFold\n",
    "pipeline = Pipeline([('vectorizer', CountVectorizer()), \n",
    "    ('classifier', MultinomialNB()) ])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c325b44a-81fd-4aa4-839d-508a68182def",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "kf = KFold(n_splits=5, shuffle = True, random_state=0)\n",
    "param_grid_nb = {\n",
    "    'vectorizer__max_features': [100, 200,300,400,500,600,700,800,900,1000,2000,4000,6000,None],\n",
    "    'vectorizer__ngram_range': [(1, 1)],\n",
    "    'classifier__alpha': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0],\n",
    "    'classifier__fit_prior': [True, False]\n",
    "    \n",
    "}\n",
    "\"\"\"\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid_nb,\n",
    "    cv = kf,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\"\"\"\n",
    "hyperparamater_tune(pipeline, param_grid_nb, preprocessed_train, df_train['labels'])               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cdb8ac-9303-4af5-94f0-8e09f1740029",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "kf = KFold(n_splits=5, shuffle = True, random_state=0)\n",
    "param_grid_nb = {\n",
    "    'vectorizer__max_features': [100, 200,300,400,500,600,700,800,900,1000,2000,4000,6000,None],\n",
    "    'vectorizer__ngram_range': [(1, 2)],\n",
    "    'classifier__alpha': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0],\n",
    "    'classifier__fit_prior': [True, False]\n",
    "    \n",
    "}\n",
    "\"\"\"\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid_nb,\n",
    "    cv = kf,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\"\"\"\n",
    "hyperparamater_tune(pipeline, param_grid_nb, preprocessed_train, df_train['labels'])               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100a190c-fa5b-4e12-b111-bf4d268a2b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MultinomialNB optimized unigram\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer(max_features = 900, ngram_range = (1,1))\n",
    "X_train = vectorizer.fit_transform(preprocessed_train)\n",
    "X_test = vectorizer.transform(preprocessed_test)\n",
    "clf = MultinomialNB(alpha=1, fit_prior=True)\n",
    "clf.fit(X_train, df_train['labels'])\n",
    "y_pred_nb_u = clf.predict(X_test)\n",
    "print(accuracy_score(df_test['labels'], y_pred_nb_u))\n",
    "print(recall_score(df_test['labels'],y_pred_nb_u))\n",
    "print(precision_score(df_test['labels'],y_pred_nb_u))\n",
    "print(f1_score(df_test['labels'],y_pred_nb_u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ea4c2a-7445-415f-bb35-f6645d0e659a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "def get_feature_importance_nb(vectorizer, nb_model):\n",
    "    # Get feature log probabilities for each class\n",
    "    feature_prob = nb_model.feature_log_prob_\n",
    "    \n",
    "    # Convert log probabilities to actual probabilities\n",
    "    feature_prob = np.exp(feature_prob)\n",
    "    \n",
    "    # Calculate difference in probabilities between classes\n",
    "    # This shows how discriminative each feature is\n",
    "    prob_diff = np.abs(feature_prob[1] - feature_prob[0])\n",
    "    \n",
    "    # Create DataFrame with features and their importance\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Class_0_Prob': feature_prob[0],\n",
    "        'Class_1_Prob': feature_prob[1],\n",
    "        'Importance': prob_diff\n",
    "    })\n",
    "    \n",
    "    return importance_df.sort_values('Importance', ascending=False)\n",
    "\n",
    "# Get feature importance\n",
    "importance_df = get_feature_importance_nb(vectorizer, clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4d860b-31b8-43a5-832c-29dcdabe417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874144d3-fc91-4af6-893e-a954e3662b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "\n",
    "# For each class\n",
    "for i, class_label in enumerate(clf.classes_):\n",
    "    # Get the feature log probabilities for this class\n",
    "    log_probs = np.exp(clf.feature_log_prob_[i])\n",
    "    \n",
    "    # Get the indices of top n features\n",
    "    top_indices = np.argsort(log_probs)[-5:][::-1]\n",
    "    \n",
    "    # Create a DataFrame with feature names and their probabilities\n",
    "    top_features_df = pd.DataFrame({\n",
    "        'Feature': feature_names[top_indices],\n",
    "        'Probability': log_probs[top_indices]\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nTop {5} features for class {class_label}:\")\n",
    "    print(top_features_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388ec55c-e774-4480-ba49-e33e763ac1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815f4bb7-7186-413c-9f0f-2d0c64fcd9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MultinomialNB optimized unigram+bigram\n",
    "vectorizer = CountVectorizer(max_features = 900, ngram_range = (1,2))\n",
    "X_train = vectorizer.fit_transform(preprocessed_train)\n",
    "X_test = vectorizer.transform(preprocessed_test)\n",
    "clf = MultinomialNB(alpha=0.6, fit_prior=True)\n",
    "clf.fit(X_train, df_train['labels'])\n",
    "y_pred_nb_b = clf.predict(X_test)\n",
    "#print(accuracy_score(df_test['labels'], y_pred))\n",
    "#print(recall_score(df_test['labels'],y_pred))\n",
    "#print(precision_score(df_test['labels'],y_pred))\n",
    "#print(f1_score(df_test['labels'],y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e85aff0-f4ce-44c3-a2f9-defe482b3ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plotly==5.24.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9576c9bd-cd9f-429a-b134-ef2f42d898ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "# Create sample data\n",
    "data = {\n",
    "    'Metrics': ['Accuracy', 'Precision', 'Recall', 'F1-Score'] * 2,\n",
    "    'Model': ['Unigram'] * 4 + ['Unigram + Bigram'] * 4,\n",
    "    'Values': [0.89375, 0.925, 0.87059, 0.89697,  # Model A values\n",
    "               0.8625, 0.95, 0.80851, 0.87356]   # Model B values\n",
    "}\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create the plot\n",
    "fig = px.bar(df,\n",
    "             x='Metrics',\n",
    "             y='Values',\n",
    "             color='Model',\n",
    "             text= data['Values'],\n",
    "             title='Multinomial Naive Bayes classifiers',\n",
    "             barmode='group')\n",
    "\n",
    "fig.update_layout(\n",
    "    font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=32,\n",
    "        color=\"RebeccaPurple\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Save as HTML file\n",
    "fig.write_html(\"naive_bayes.html\")\n",
    "\n",
    "# Show plot\n",
    "fig.show()\n",
    "\n",
    "# Optional: Save as static image\n",
    "fig.write_image(\"naive_bayes.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c052120-5371-457d-9fae-5ce79ba6ed6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ed03a8-e81c-4364-a362-9469c53ea555",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U kaleido\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6245b03-3283-4948-9141-a399112897a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "pipeline = Pipeline([('vectorizer', CountVectorizer(ngram_range = (1,1))), \n",
    "    ('classifier', LogisticRegression()) ])\n",
    "param_grid_logreg = {\n",
    "    'classifier__C': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "}\n",
    "\n",
    "hyperparamater_tune(pipeline, param_grid_logreg, preprocessed_train, df_train['labels'])         \n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range = (1,1))\n",
    "X_train = vectorizer.fit_transform(preprocessed_train)\n",
    "X_test = vectorizer.transform(preprocessed_test)\n",
    "clf = LogisticRegression(C=0.1)\n",
    "clf.fit(X_train, df_train['labels'])\n",
    "y_pred_logres = clf.predict(X_test)\n",
    "print(accuracy_score(df_test['labels'], y_pred_logres))\n",
    "print(recall_score(df_test['labels'],y_pred_logres))\n",
    "print(precision_score(df_test['labels'],y_pred_logres))\n",
    "print(f1_score(df_test['labels'],y_pred_logres))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f4ca05-19cd-4776-9ff8-42f9c1e5f5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('vectorizer', CountVectorizer(ngram_range = (1,2))), \n",
    "    ('classifier', LogisticRegression()) ])\n",
    "\n",
    "hyperparamater_tune(pipeline, param_grid_logreg, preprocessed_train, df_train['labels'])         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4c4915-168f-4bb7-b671-23ca4eed84c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range = (1,2))\n",
    "X_train = vectorizer.fit_transform(preprocessed_train)\n",
    "X_test = vectorizer.transform(preprocessed_test)\n",
    "clf = LogisticRegression(C=0.7)\n",
    "clf.fit(X_train, df_train['labels'])\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(df_test['labels'], y_pred))\n",
    "print(recall_score(df_test['labels'],y_pred))\n",
    "print(precision_score(df_test['labels'],y_pred))\n",
    "print(f1_score(df_test['labels'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8551773e-d9ae-4b4a-8a80-c1bdcff17e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Metrics': ['Accuracy', 'Precision', 'Recall', 'F1-Score'] * 2,\n",
    "    'Model': ['Unigram'] * 4 + ['Unigram + Bigram'] * 4,\n",
    "    'Values': [0.88125, 0.9375, 0.84270, 0.88757,  # Model A values\n",
    "               0.8625, 0.9125, 0.82954, 0.87905]   # Model B values\n",
    "}\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create the plot\n",
    "fig = px.bar(df,\n",
    "             x='Metrics',\n",
    "             y='Values',\n",
    "             color='Model',\n",
    "             text = data['Values'],\n",
    "             title='Logistic Regression classifiers',\n",
    "             barmode='group')\n",
    "\n",
    "fig.update_layout(\n",
    "    font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=32,\n",
    "        color=\"RebeccaPurple\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Save as HTML file\n",
    "fig.write_html(\"Logistic.html\")\n",
    "\n",
    "# Show plot\n",
    "fig.show()\n",
    "\n",
    "# Optional: Save as static image\n",
    "fig.write_image(\"Logistic.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270bfb67-c6bb-4a31-b5c7-7036f34038a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc6ed10-3720-44e0-b021-6c54d8f893e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5f025c-a9c9-43a6-8528-9cb676295a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X_train_nofs,df_train['labels'])\n",
    "clf.score(X_test_nofs,df_test['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e8d487-e966-4d07-b783-d3c58be9332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "pipeline = Pipeline([('vectorizer', CountVectorizer(ngram_range = (1,1))), \n",
    "    ('classifier', DecisionTreeClassifier(random_state = 0)) ])\n",
    "param_grid_dt = {\n",
    "    'classifier__min_samples_leaf': np.arange(1,105,2),\n",
    "    'classifier__min_samples_split': np.arange(2,105,2)\n",
    "}\n",
    "\n",
    "hyperparamater_tune(pipeline, param_g33rid_dt, preprocessed_train, df_train['labels'])         \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c8d761-150a-424d-82d7-1148088315b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range = (1,1))\n",
    "X_train = vectorizer.fit_transform(preprocessed_train)\n",
    "X_test = vectorizer.transform(preprocessed_test)\n",
    "clf = DecisionTreeClassifier(random_state = 0, min_samples_leaf = 66, min_samples_split = 2)\n",
    "clf.fit(X_train, df_train['labels'])\n",
    "y_pred_dt= clf.predict(X_test)\n",
    "print(accuracy_score(df_test['labels'], y_pred_dt))\n",
    "print(recall_score(df_test['labels'],y_pred_dt))\n",
    "print(precision_score(df_test['labels'],y_pred_dt))\n",
    "print(f1_score(df_test['labels'],y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8dd299-0426-41b8-a506-f42ebea5d7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "pipeline = Pipeline([('vectorizer', CountVectorizer(ngram_range = (1,2))), \n",
    "    ('classifier', DecisionTreeClassifier(random_state = 0)) ])\n",
    "param_grid_dt = {\n",
    "    'classifier__min_samples_leaf': np.arange(1,105,2),\n",
    "    'classifier__min_samples_split': np.arange(2,105,2)\n",
    "}\n",
    "\n",
    "hyperparamater_tune(pipeline, param_grid_dt, preprocessed_train, df_train['labels'])         \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf2cfba-3c7a-416d-ae9c-0660daef876e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range = (1,2))\n",
    "X_train = vectorizer.fit_transform(preprocessed_train)\n",
    "X_test = vectorizer.transform(preprocessed_test)\n",
    "clf = DecisionTreeClassifier(random_state = 0, min_samples_leaf = 1, min_samples_split = 4)\n",
    "clf.fit(X_train, df_train['labels'])\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(df_test['labels'], y_pred))\n",
    "print(recall_score(df_test['labels'],y_pred))\n",
    "print(precision_score(df_test['labels'],y_pred))\n",
    "print(f1_score(df_test['labels'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a44bf9-0804-4703-896c-6601c41f5f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Metrics': ['Accuracy', 'Precision', 'Recall', 'F1-Score'] * 2,\n",
    "    'Model': ['Unigram'] * 4 + ['Unigram + Bigram'] * 4,\n",
    "    'Values': [0.61875, 0.7125, 0.6, 0.6514,  # Model A values\n",
    "               0.6625, 0.7375, 0.6413, 0.6860]   # Model B values\n",
    "}\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create the plot\n",
    "fig = px.bar(df,\n",
    "             x='Metrics',\n",
    "             y='Values',\n",
    "             color='Model',\n",
    "             text = data['Values'],\n",
    "             title='Decision Tree classifiers',\n",
    "             barmode='group')\n",
    "\n",
    "fig.update_layout(\n",
    "    font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=32,\n",
    "        color=\"RebeccaPurple\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Save as HTML file\n",
    "fig.write_html(\"DT.html\")\n",
    "\n",
    "# Show plot\n",
    "fig.show()\n",
    "\n",
    "# Optional: Save as static image\n",
    "fig.write_image(\"DT.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efea11ce-8f51-4447-beb8-e44f62c53ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "pipeline = Pipeline([('vectorizer', CountVectorizer(ngram_range = (1,1))), \n",
    "    ('classifier', RandomForestClassifier(random_state = 0)) ])\n",
    "param_grid_rf = {\n",
    "    'classifier__min_samples_leaf': np.arange(1,101,10),\n",
    "    'classifier__n_estimators': [50,100,150,200]\n",
    "}\n",
    "\n",
    "hyperparamater_tune(pipeline, param_grid_rf, preprocessed_train, df_train['labels'])         \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8412812-3ce7-4a1c-8971-9b61c97cf90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range = (1,1))\n",
    "X_train = vectorizer.fit_transform(preprocessed_train)\n",
    "X_test = vectorizer.transform(preprocessed_test)\n",
    "clf = RandomForestClassifier(random_state = 0, min_samples_leaf = 1, n_estimators = 100)\n",
    "clf.fit(X_train, df_train['labels'])\n",
    "y_pred_rf_u = clf.predict(X_test)\n",
    "#print(accuracy_score(df_test['labels'], y_pred))\n",
    "#print(recall_score(df_test['labels'],y_pred))\n",
    "#print(precision_score(df_test['labels'],y_pred))\n",
    "#print(f1_score(df_test['labels'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7189fa64-4021-4a3d-b60e-63d9b228e68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('vectorizer', CountVectorizer(ngram_range = (1,2))), \n",
    "    ('classifier', RandomForestClassifier(random_state = 0)) ])\n",
    "param_grid_rf = {\n",
    "    'classifier__min_samples_leaf': np.arange(1,101,10),\n",
    "    'classifier__n_estimators': [50,100,150,200]\n",
    "}\n",
    "\n",
    "hyperparamater_tune(pipeline, param_grid_rf, preprocessed_train, df_train['labels'])         \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0646595-be08-44c4-9cd7-d82648fc69b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range = (1,2))\n",
    "X_train = vectorizer.fit_transform(preprocessed_train)\n",
    "X_test = vectorizer.transform(preprocessed_test)\n",
    "clf = RandomForestClassifier(random_state = 0, min_samples_leaf = 1, n_estimators = 150)\n",
    "clf.fit(X_train, df_train['labels'])\n",
    "y_pred_rf_b = clf.predict(X_test)\n",
    "print(accuracy_score(df_test['labels'], y_pred))\n",
    "print(recall_score(df_test['labels'],y_pred))\n",
    "print(precision_score(df_test['labels'],y_pred))\n",
    "print(f1_score(df_test['labels'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaaf1a0-92fe-431f-93c9-5e4c989ac24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Metrics': ['Accuracy', 'Precision', 'Recall', 'F1-Score'] * 2,\n",
    "    'Model': ['Unigram'] * 4 + ['Unigram + Bigram'] * 4,\n",
    "    'Values': [0.79375, 0.7625, 0.8133, 0.7871,  # Model A values\n",
    "               0.79375, 0.9, 0.7423, 0.8136]   # Model B values\n",
    "}\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create the plot\n",
    "fig = px.bar(df,\n",
    "             x='Metrics',\n",
    "             y='Values',\n",
    "             text = data['Values'],\n",
    "             color='Model',\n",
    "             title='Random Forest classifiers',\n",
    "             barmode='group')\n",
    "\n",
    "fig.update_layout(\n",
    "    font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=32,\n",
    "        color=\"RebeccaPurple\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Save as HTML file\n",
    "fig.write_html(\"rf.html\")\n",
    "\n",
    "# Show plot\n",
    "fig.show()\n",
    "\n",
    "# Optional: Save as static image\n",
    "fig.write_image(\"rf.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d47b229-8713-4aad-aebd-355442c171e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "def train_and_eval(clf, X,y, X_t, y_t):\n",
    "    vectorizer = CountVectorizer()\n",
    "    X_train = vectorizer.fit_transform(X)\n",
    "    X_test = vectorizer.transform(X_t)\n",
    "    clf.fit(X_train, y)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(accuracy_score(y_t, y_pred))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6faafd-b965-4485-9c93-c3e5072b31a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896e3eaf-c30a-4936-b970-319b58ec7228",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.evaluate import mcnemar_table\n",
    "from mlxtend.evaluate import mcnemar\n",
    "chi2, p_value = mcnemar(mcnemar_table(df_test['labels'], \n",
    "                                      np.array(y_pred_nb_u), \n",
    "                                      np.array(y_pred_nb_b)),\n",
    "                        corrected=False)\n",
    "print('Q: %.3f' % chi2)\n",
    "print('p-value: %.3f' % p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6301a56c-bd63-418d-b778-5c1942a4b405",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2, p_value = mcnemar(mcnemar_table(df_test['labels'], \n",
    "                                      np.array(y_pred_logres), \n",
    "                                      np.array(y_pred)),\n",
    "                        corrected=False)\n",
    "print('Q: %.3f' % chi2)\n",
    "print('p-value: %.3f' % p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cc7547-193a-453b-a04f-687d6537a43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2, p_value = mcnemar(mcnemar_table(df_test['labels'], \n",
    "                                      np.array(y_pred_dt), \n",
    "                                      np.array(y_pred)),\n",
    "                        corrected=False)\n",
    "print('Q: %.3f' % chi2)\n",
    "print('p-value: %.3f' % p_value)y_pred_nb_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75559be9-b7ae-4d74-b897-a2bb8c569943",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2, p_value = mcnemar(mcnemar_table(df_test['labels'], \n",
    "                                      np.array(y_pred_logres), \n",
    "                                      np.array(y_pred_nb_u)),\n",
    "                        corrected=False)\n",
    "print('Q: %.3f' % chi2)\n",
    "print('p-value: %.3f' % p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee95311-6c56-47dd-8d4d-92488036bdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2, p_value = mcnemar(mcnemar_table(df_test['labels'], \n",
    "                                      np.array(y_pred_logres), \n",
    "                                      np.array(y_pred_rf_u)),\n",
    "                        corrected=False)\n",
    "print('Q: %.3f' % chi2)\n",
    "print('p-value: %.3f' % p_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
